{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a682fc6e-9887-47e6-8be8-bdacd1465863",
   "metadata": {},
   "source": [
    "### This is a comparision between the ILP and the SSMOSP approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c47bc1-9a14-4f1a-9368-83c795c4a75e",
   "metadata": {},
   "source": [
    "#### Note: The graph data structure is stored as a JSON file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f68f2d4e-73ca-46d0-bfe7-2771c574abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### This is the ILP approach\n",
    "# ############################################ NOTE: This program randomly generates graph which might NOT necessarily be DAGs ####################################\n",
    "\n",
    "# import gurobipy as gp\n",
    "# from gurobipy import GRB\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# import json\n",
    "\n",
    "# # Generate a 50-node graph with random edges and weights\n",
    "# def generate_graph(num_nodes, num_edges):\n",
    "#     nodes = [f'n{i}' for i in range(num_nodes)]\n",
    "#     edges = {}\n",
    "#     for _ in range(num_edges):\n",
    "#         u = random.choice(nodes)\n",
    "#         v = random.choice(nodes)\n",
    "#         if u != v and (u, v) not in edges:\n",
    "#             weight = random.randint(-10, 10)\n",
    "#             edges[(u, v)] = weight\n",
    "#     return nodes, edges\n",
    "\n",
    "# # Parameters\n",
    "# num_nodes = 50\n",
    "# num_edges = 200\n",
    "# nodes, edges = generate_graph(num_nodes, num_edges)\n",
    "# C = 20\n",
    "\n",
    "# # Convert the tuple keys to strings for JSON compatibility\n",
    "# json_edges = {f\"{u},{v}\": weight for (u, v), weight in edges.items()}\n",
    "\n",
    "# # Save the generated graph (edges) to a JSON file for the second program\n",
    "# with open(\"graph_data.json\", \"w\") as f:\n",
    "#     json.dump(json_edges, f)\n",
    "\n",
    "# # Convert edges to (reward, loss) format\n",
    "# converted_edges = {}\n",
    "# for (u, v), weight in edges.items():\n",
    "#     if weight > 0:\n",
    "#         converted_edges[(u, v)] = (weight, 0)\n",
    "#     else:\n",
    "#         converted_edges[(u, v)] = (0, -weight)\n",
    "\n",
    "# # Create a new model\n",
    "# m = gp.Model()\n",
    "\n",
    "# # Create variables\n",
    "# x = {}\n",
    "# for u, v in converted_edges:\n",
    "#     x[u, v] = m.addVar(vtype=GRB.BINARY, name=f\"x_{u}_{v}\")\n",
    "\n",
    "# # Set objective function to maximize total reward\n",
    "# m.setObjective(gp.quicksum(x[u, v] * converted_edges[u, v][0] for u, v in converted_edges), GRB.MAXIMIZE)\n",
    "\n",
    "# # Add constraints\n",
    "# source_node = 'n0'\n",
    "# target_node = f'n{num_nodes-1}'\n",
    "\n",
    "# # Constraint 1: The number of edges leaving source_node is 1\n",
    "# m.addConstr(gp.quicksum(x[source_node, v] for v in nodes if (source_node, v) in converted_edges) == 1, \"c1\")\n",
    "\n",
    "# # Constraint 2: The number of edges entering target_node is 1\n",
    "# m.addConstr(gp.quicksum(x[u, target_node] for u in nodes if (u, target_node) in converted_edges) == 1, \"c2\")\n",
    "\n",
    "# # Constraint 3: For all other vertices, the number of edges leaving them equals the number of edges entering them\n",
    "# for p in nodes:\n",
    "#     if p not in [source_node, target_node]:\n",
    "#         m.addConstr(\n",
    "#             gp.quicksum(x[p, q] for q in nodes if (p, q) in converted_edges) -\n",
    "#             gp.quicksum(x[r, p] for r in nodes if (r, p) in converted_edges) == 0,\n",
    "#             f\"flow_{p}\"\n",
    "#         )\n",
    "\n",
    "# # Constraint: The total loss should be at most C\n",
    "# m.addConstr(gp.quicksum(x[u, v] * converted_edges[u, v][1] for u, v in converted_edges) <= C, \"loss_constraint\")\n",
    "\n",
    "# # Solve the model\n",
    "# m.optimize()\n",
    "\n",
    "# # Extract the solution edges and calculate reward and penalty\n",
    "# solution_edges = []\n",
    "# total_reward = 0\n",
    "# total_negative_weight = 0\n",
    "\n",
    "# if m.status == GRB.OPTIMAL:\n",
    "#     for u, v in converted_edges:\n",
    "#         if x[u, v].X > 0.5:\n",
    "#             solution_edges.append((u, v))\n",
    "#             reward, loss = converted_edges[u, v]\n",
    "#             if reward > 0:\n",
    "#                 total_reward += reward\n",
    "#             if loss > 0:\n",
    "#                 total_negative_weight += loss\n",
    "\n",
    "#     # Print the best path\n",
    "#     print(\"Best path:\")\n",
    "#     for u, v in solution_edges:\n",
    "#         print(f\"{u} -> {v} (weight: {converted_edges[u, v][0] if converted_edges[u, v][0] > 0 else -converted_edges[u, v][1]})\")\n",
    "\n",
    "#     # Print total reward and total negative weight\n",
    "#     print(f\"Total reward: {total_reward}\")\n",
    "#     print(f\"Total negative weight: {total_negative_weight}\")\n",
    "# else:\n",
    "#     print(\"No valid path found\")\n",
    "\n",
    "# # Create the graph using networkx\n",
    "# G = nx.DiGraph()\n",
    "# for (u, v), (reward, loss) in converted_edges.items():\n",
    "#     G.add_edge(u, v, weight=reward if reward > 0 else -loss)\n",
    "\n",
    "# # Define positions for nodes\n",
    "# pos = nx.spring_layout(G)\n",
    "\n",
    "# # Draw the graph\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# nx.draw_networkx_nodes(G, pos, node_size=500, node_color='lightblue')\n",
    "# nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "# # Draw all edges\n",
    "# nx.draw_networkx_edges(G, pos, edgelist=G.edges(), arrowstyle='-|>', arrowsize=15, edge_color='gray')\n",
    "\n",
    "# # Highlight the solution edges\n",
    "# nx.draw_networkx_edges(G, pos, edgelist=solution_edges, arrowstyle='-|>', arrowsize=15, edge_color='r', width=2)\n",
    "\n",
    "# # Draw edge labels\n",
    "# edge_labels = {(u, v): f\"{G[u][v]['weight']}\" for u, v in G.edges()}\n",
    "# nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.title(f\"Most Rewarding Path with Total Loss ≤ {C}\", fontsize=16)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe24a52-ca4e-4d72-90fb-129f4b9f8811",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279524d3-5cbd-4926-ad23-a2674f94195f",
   "metadata": {},
   "source": [
    "### The code for random generation is modified such that it only generates DAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c95ead8-c319-4257-b27b-1545627bc9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (linux64 - \"Ubuntu 24.04.1 LTS\")\n",
      "\n",
      "CPU model: AMD Ryzen 3 3250U with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 2 physical cores, 4 logical processors, using up to 4 threads\n",
      "\n",
      "Optimize a model with 101 rows, 500 columns and 1239 nonzeros\n",
      "Model fingerprint: 0xb8f1336e\n",
      "Variable types: 0 continuous, 500 integer (500 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+02]\n",
      "  Objective range  [1e+00, 1e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+01]\n",
      "Found heuristic solution: objective 199.0000000\n",
      "Presolve removed 101 rows and 500 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 4 available processors)\n",
      "\n",
      "Solution count 1: 199 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.990000000000e+02, best bound 1.990000000000e+02, gap 0.0000%\n",
      "Best path:\n",
      "n0 -> n95 (weight: 95)\n",
      "n95 -> n74 (weight: 33)\n",
      "n74 -> n99 (weight: 71)\n",
      "Total reward: 199\n",
      "Total negative weight: 0\n"
     ]
    }
   ],
   "source": [
    "### modified code so that it only generates DAGs \n",
    "\n",
    "import random\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import json\n",
    "\n",
    "# Generate a DAG with random edges and weights\n",
    "def generate_dag(num_nodes, num_edges):\n",
    "    nodes = [f'n{i}' for i in range(num_nodes)]\n",
    "    \n",
    "    # Assign topological order to nodes (just shuffle them)\n",
    "    topological_order = nodes.copy()\n",
    "    random.shuffle(topological_order)\n",
    "    \n",
    "    edges = {}\n",
    "    while len(edges) < num_edges:\n",
    "        u, v = random.sample(topological_order, 2)\n",
    "        # Ensure the edge follows topological order (u appears before v)\n",
    "        if topological_order.index(u) < topological_order.index(v):\n",
    "            if (u, v) not in edges:\n",
    "                weight = random.randint(-100, 100)\n",
    "                edges[(u, v)] = weight\n",
    "    return nodes, edges\n",
    "\n",
    "# Parameters\n",
    "num_nodes = 100\n",
    "num_edges = 500\n",
    "nodes, edges = generate_dag(num_nodes, num_edges)\n",
    "C = 50\n",
    "\n",
    "# Save the generated graph (edges) to a JSON file for the second program\n",
    "edges_str_keys = {f\"{u},{v}\": weight for (u, v), weight in edges.items()}\n",
    "with open(\"graph_data.json\", \"w\") as f:\n",
    "    json.dump(edges_str_keys, f)\n",
    "\n",
    "# Convert edges to (reward, loss) format\n",
    "converted_edges = {}\n",
    "for (u, v), weight in edges.items():\n",
    "    if weight > 0:\n",
    "        converted_edges[(u, v)] = (weight, 0)\n",
    "    else:\n",
    "        converted_edges[(u, v)] = (0, -weight)\n",
    "\n",
    "# Create a new model\n",
    "m = gp.Model()\n",
    "\n",
    "# Create variables\n",
    "x = {}\n",
    "for u, v in converted_edges:\n",
    "    x[u, v] = m.addVar(vtype=GRB.BINARY, name=f\"x_{u}_{v}\")\n",
    "\n",
    "# Set objective function to maximize total reward\n",
    "m.setObjective(gp.quicksum(x[u, v] * converted_edges[u, v][0] for u, v in converted_edges), GRB.MAXIMIZE)\n",
    "\n",
    "# Add constraints\n",
    "source_node = 'n0'\n",
    "target_node = f'n{num_nodes-1}'\n",
    "\n",
    "# Constraint 1: The number of edges leaving source_node is 1\n",
    "m.addConstr(gp.quicksum(x[source_node, v] for v in nodes if (source_node, v) in converted_edges) == 1, \"c1\")\n",
    "\n",
    "# Constraint 2: The number of edges entering target_node is 1\n",
    "m.addConstr(gp.quicksum(x[u, target_node] for u in nodes if (u, target_node) in converted_edges) == 1, \"c2\")\n",
    "\n",
    "# Constraint 3: For all other vertices, the number of edges leaving them equals the number of edges entering them\n",
    "for p in nodes:\n",
    "    if p not in [source_node, target_node]:\n",
    "        m.addConstr(\n",
    "            gp.quicksum(x[p, q] for q in nodes if (p, q) in converted_edges) -\n",
    "            gp.quicksum(x[r, p] for r in nodes if (r, p) in converted_edges) == 0,\n",
    "            f\"flow_{p}\"\n",
    "        )\n",
    "\n",
    "# Constraint: The total loss should be at most C\n",
    "m.addConstr(gp.quicksum(x[u, v] * converted_edges[u, v][1] for u, v in converted_edges) <= C, \"loss_constraint\")\n",
    "\n",
    "# Solve the model\n",
    "m.optimize()\n",
    "\n",
    "# Extract the solution edges\n",
    "solution_edges = []\n",
    "predecessors = {}\n",
    "\n",
    "if m.status == GRB.OPTIMAL:\n",
    "    for u, v in converted_edges:\n",
    "        if x[u, v].X > 0.5:  # If the edge is selected in the optimal solution\n",
    "            solution_edges.append((u, v))\n",
    "            predecessors[u] = v  # Track the next node for each node\n",
    "\n",
    "    # Reconstruct the path from the source node 'n0' to the target node\n",
    "    best_path = []\n",
    "    current_node = source_node\n",
    "\n",
    "    while current_node in predecessors:\n",
    "        next_node = predecessors[current_node]\n",
    "        best_path.append((current_node, next_node))\n",
    "        current_node = next_node\n",
    "\n",
    "    # Print the best path in the correct order (starting from the source)\n",
    "    print(\"Best path:\")\n",
    "    total_reward = 0\n",
    "    total_negative_weight = 0\n",
    "    for u, v in best_path:\n",
    "        reward, loss = converted_edges[u, v]\n",
    "        print(f\"{u} -> {v} (weight: {reward if reward > 0 else -loss})\")\n",
    "        if reward > 0:\n",
    "            total_reward += reward\n",
    "        if loss > 0:\n",
    "            total_negative_weight += loss\n",
    "\n",
    "    # Print total reward and total negative weight\n",
    "    print(f\"Total reward: {total_reward}\")\n",
    "    print(f\"Total negative weight: {total_negative_weight}\")\n",
    "else:\n",
    "    print(\"No valid path found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7549e75-df2d-4a5d-a2ab-b97a1606268b",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d4822-8142-4671-83e3-31feb2abf596",
   "metadata": {},
   "source": [
    "### Graph data verification (for JSON graph data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e072cb21-02a5-43e3-9701-6ece5d534f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 90\n",
      "Number of edges: 500\n",
      "Number of paths from 0 to 99: 2\n",
      "All paths from 0 to 99:\n",
      "Path 1: [0, 95, 74, 99] (Reward: 199, Penalty: 0)\n",
      "Path 2: [0, 52, 81, 74, 99] (Reward: 125, Penalty: 54)\n",
      "\n",
      "Path Statistics:\n",
      "Shortest path (#nodes, reward - penalty): 4, 199 - 0\n",
      "Longest path  (#nodes, reward - penalty): 5, 125 - 54\n",
      "Average path  (#nodes, reward - penalty): 4.50, 162.00 - 27.00\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the graph data\n",
    "with open(\"graph_data.json\", \"r\") as f:\n",
    "    json_edges = json.load(f)\n",
    "\n",
    "# Convert string keys back to tuples of node names\n",
    "edges = {tuple(map(str.strip, key.split(','))): value for key, value in json_edges.items()}\n",
    "\n",
    "# Create a graph representation\n",
    "G = defaultdict(list)\n",
    "for (u, v), weight in edges.items():\n",
    "    u = int(u[1:])  # Convert node label from 'nX' to integer X\n",
    "    v = int(v[1:])  # Same here\n",
    "    G[u].append((v, weight))\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Number of nodes: {len(G)}\")\n",
    "print(f\"Number of edges: {sum(len(v) for v in G.values())}\")\n",
    "\n",
    "# Function to find all paths\n",
    "def find_all_paths(graph, start, end, path=[]):\n",
    "    path = path + [start]\n",
    "    if start == end:\n",
    "        return [path]\n",
    "    if start not in graph:\n",
    "        return []\n",
    "    paths = []\n",
    "    for node, _ in graph[start]:\n",
    "        if node not in path:\n",
    "            new_paths = find_all_paths(graph, node, end, path)\n",
    "            for new_path in new_paths:\n",
    "                paths.append(new_path)\n",
    "    return paths\n",
    "\n",
    "# Function to calculate reward and penalty for a path\n",
    "def calculate_reward_penalty(graph, path):\n",
    "    reward = 0\n",
    "    penalty = 0\n",
    "    for i in range(len(path) - 1):\n",
    "        u, v = path[i], path[i+1]\n",
    "        weight = next(w for node, w in graph[u] if node == v)\n",
    "        if weight > 0:\n",
    "            reward += weight\n",
    "        else:\n",
    "            penalty -= weight\n",
    "    return reward, penalty\n",
    "\n",
    "# Find all paths from source to terminal\n",
    "all_paths = find_all_paths(G, 0, 99)\n",
    "\n",
    "print(f\"Number of paths from 0 to 99: {len(all_paths)}\")\n",
    "\n",
    "if all_paths:\n",
    "    print(\"All paths from 0 to 99:\")\n",
    "    for i, path in enumerate(all_paths, 1):\n",
    "        reward, penalty = calculate_reward_penalty(G, path)\n",
    "        print(f\"Path {i}: {path} (Reward: {reward}, Penalty: {penalty})\")\n",
    "\n",
    "# Calculate statistics about the paths\n",
    "if all_paths:\n",
    "    path_stats = [(len(path), *calculate_reward_penalty(G, path)) for path in all_paths]\n",
    "    \n",
    "    print(f\"\\nPath Statistics:\")\n",
    "    shortest_path = min(path_stats, key=lambda x: x[0])\n",
    "    longest_path = max(path_stats, key=lambda x: x[0])\n",
    "    avg_nodes = sum(stat[0] for stat in path_stats) / len(path_stats)\n",
    "    avg_reward = sum(stat[1] for stat in path_stats) / len(path_stats)\n",
    "    avg_penalty = sum(stat[2] for stat in path_stats) / len(path_stats)\n",
    "    \n",
    "    print(f\"Shortest path (#nodes, reward - penalty): {shortest_path[0]}, {shortest_path[1]} - {shortest_path[2]}\")\n",
    "    print(f\"Longest path  (#nodes, reward - penalty): {longest_path[0]}, {longest_path[1]} - {longest_path[2]}\")\n",
    "    print(f\"Average path  (#nodes, reward - penalty): {avg_nodes:.2f}, {avg_reward:.2f} - {avg_penalty:.2f}\")\n",
    "else:\n",
    "    print(\"No paths found from 0 to 99\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b219daf2-511d-40d4-b922-e4546c14d555",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc6591-0416-4ab4-b908-992786e3214c",
   "metadata": {},
   "source": [
    "### SSMOSP Extend and Merge Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6caa91a6-07f5-4467-8da7-ccdcf7b3eb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Square Root Bucketing:\n",
      "Maximum Reward: 199\n",
      "Path: [('n0', 'n95', 95), ('n95', 'n74', 33), ('n74', 'n99', 71)]\n",
      "\n",
      "Using Double Logarithmic Bucketing:\n",
      "Maximum Reward: 199\n",
      "Path: [('n0', 'n95', 95), ('n95', 'n74', 33), ('n74', 'n99', 71)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, u, v, weight):\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        self.weight = weight\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, nodes):\n",
    "        self.V = len(nodes)\n",
    "        self.adj = defaultdict(list)\n",
    "        self.incoming = defaultdict(list)\n",
    "        self.node_map = {name: idx for idx, name in enumerate(nodes)}\n",
    "        self.reverse_node_map = {idx: name for name, idx in self.node_map.items()}\n",
    "\n",
    "    def add_edge(self, u, v, weight):\n",
    "        u_idx = self.node_map[u]\n",
    "        v_idx = self.node_map[v]\n",
    "        edge = Edge(u_idx, v_idx, weight)\n",
    "        self.adj[u_idx].append(edge)\n",
    "        self.incoming[v_idx].append(edge)\n",
    "\n",
    "    def topological_sort(self):\n",
    "        in_degree = {i: 0 for i in range(self.V)}\n",
    "        for u in self.adj:\n",
    "            for edge in self.adj[u]:\n",
    "                in_degree[edge.v] += 1\n",
    "\n",
    "        queue = deque([v for v in range(self.V) if in_degree[v] == 0])\n",
    "        top_order = []\n",
    "\n",
    "        while queue:\n",
    "            u = queue.popleft()\n",
    "            top_order.append(u)\n",
    "            for edge in self.adj[u]:\n",
    "                in_degree[edge.v] -= 1\n",
    "                if in_degree[edge.v] == 0:\n",
    "                    queue.append(edge.v)\n",
    "\n",
    "        return top_order\n",
    "\n",
    "def calculate_position_sqrt(q):\n",
    "    return (int(math.sqrt(q[0] + 1)), int(math.sqrt(q[1] + 1)))\n",
    "\n",
    "def calculate_position_double_log(q):\n",
    "    reward_log = math.log(q[0] + 1)\n",
    "    neg_weight_log = math.log(q[1] + 1)\n",
    "    return (int(math.log(reward_log + 1)), int(math.log(neg_weight_log + 1)))\n",
    "\n",
    "def ExtendAndMerge(R, Q, e, bound, calculate_position_func):\n",
    "    for p in Q.values():\n",
    "        if e.weight >= 0:\n",
    "            q = (p[0] + e.weight, p[1], p, e)\n",
    "        else:\n",
    "            q = (p[0], p[1] - e.weight, p, e)\n",
    "        \n",
    "        if q[1] <= bound:\n",
    "            pos = calculate_position_func(q)\n",
    "            if pos not in R or R[pos][0] < q[0]:\n",
    "                R[pos] = q\n",
    "\n",
    "def reconstruct_path(p):\n",
    "    path = []\n",
    "    while p[2] is not None:\n",
    "        path.append(p[3])\n",
    "        p = p[2]\n",
    "    return list(reversed(path))\n",
    "\n",
    "def ModifiedSSMOSP(G, s, t, bound, calculate_position_func):\n",
    "    TopOrder = G.topological_sort()\n",
    "    Π = {v: {} for v in range(G.V)}\n",
    "    Π[s][0] = (0, 0, None, None)\n",
    "\n",
    "    for v in TopOrder:\n",
    "        for e in G.incoming[v]:\n",
    "            ExtendAndMerge(Π[v], Π[e.u], e, bound, calculate_position_func)\n",
    "    \n",
    "    if Π[t]:\n",
    "        best_path = max(Π[t].values(), key=lambda p: p[0])\n",
    "        return best_path[0], reconstruct_path(best_path)\n",
    "    else:\n",
    "        return None, []\n",
    "\n",
    "# Load the JSON data generated by the previous program\n",
    "with open(\"graph_data.json\", \"r\") as f:\n",
    "    edges = json.load(f)\n",
    "\n",
    "nodes = list(set([u.split(\",\")[0] for u in edges] + [v.split(\",\")[1] for v in edges]))\n",
    "graph = Graph(nodes)\n",
    "\n",
    "for edge, weight in edges.items():\n",
    "    u, v = edge.split(\",\")\n",
    "    graph.add_edge(u, v, weight)\n",
    "\n",
    "# Source, target, and bound\n",
    "source = \"n0\"\n",
    "target = f\"n{len(nodes)-1}\"\n",
    "bound = 50  # as per the constraints\n",
    "\n",
    "# Run ModifiedSSMOSP with the alternative `calculate_position` functions for comparison\n",
    "source_idx = graph.node_map[source]\n",
    "target_idx = graph.node_map[target]\n",
    "\n",
    "print(\"Using Square Root Bucketing:\")\n",
    "max_reward_sqrt, path_sqrt = ModifiedSSMOSP(graph, source_idx, target_idx, bound, calculate_position_sqrt)\n",
    "if path_sqrt:\n",
    "    path_sqrt_edges = [(graph.reverse_node_map[edge.u], graph.reverse_node_map[edge.v], edge.weight) for edge in path_sqrt]\n",
    "    print(f\"Maximum Reward: {max_reward_sqrt}\")\n",
    "    print(\"Path:\", path_sqrt_edges)\n",
    "else:\n",
    "    print(\"No feasible path found within the bound.\")\n",
    "\n",
    "print(\"\\nUsing Double Logarithmic Bucketing:\")\n",
    "max_reward_double_log, path_double_log = ModifiedSSMOSP(graph, source_idx, target_idx, bound, calculate_position_double_log)\n",
    "if path_double_log:\n",
    "    path_double_log_edges = [(graph.reverse_node_map[edge.u], graph.reverse_node_map[edge.v], edge.weight) for edge in path_double_log]\n",
    "    print(f\"Maximum Reward: {max_reward_double_log}\")\n",
    "    print(\"Path:\", path_double_log_edges)\n",
    "else:\n",
    "    print(\"No feasible path found within the bound.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291663f-7903-4531-a751-81f6b3a28976",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb146b-fa2e-4ce1-9d99-396ef44009af",
   "metadata": {},
   "source": [
    "### Original SSMOSP Approach Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bf8c8ed-bc19-43bf-98a1-a10ab176ed7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Custom Logarithmic Bucketing:\n",
      "Maximum Reward: 199\n",
      "Path: [('n0', 'n95', 95), ('n95', 'n74', 33), ('n74', 'n99', 71)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, u, v, weight):\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        self.weight = weight\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, nodes):\n",
    "        self.V = len(nodes)\n",
    "        self.adj = defaultdict(list)\n",
    "        self.incoming = defaultdict(list)\n",
    "        self.node_map = {name: idx for idx, name in enumerate(nodes)}\n",
    "        self.reverse_node_map = {idx: name for name, idx in self.node_map.items()}\n",
    "\n",
    "    def add_edge(self, u, v, weight):\n",
    "        u_idx = self.node_map[u]\n",
    "        v_idx = self.node_map[v]\n",
    "        edge = Edge(u_idx, v_idx, weight)\n",
    "        self.adj[u_idx].append(edge)\n",
    "        self.incoming[v_idx].append(edge)\n",
    "\n",
    "    def topological_sort(self):\n",
    "        in_degree = {i: 0 for i in range(self.V)}\n",
    "        for u in self.adj:\n",
    "            for edge in self.adj[u]:\n",
    "                in_degree[edge.v] += 1\n",
    "\n",
    "        queue = deque([v for v in range(self.V) if in_degree[v] == 0])\n",
    "        top_order = []\n",
    "\n",
    "        while queue:\n",
    "            u = queue.popleft()\n",
    "            top_order.append(u)\n",
    "            for edge in self.adj[u]:\n",
    "                in_degree[edge.v] -= 1\n",
    "                if in_degree[edge.v] == 0:\n",
    "                    queue.append(edge.v)\n",
    "\n",
    "        return top_order\n",
    "\n",
    "def calculate_position_custom(q, min_reward, r):\n",
    "    reward_ratio = q[0] / min_reward\n",
    "    return int(math.log(reward_ratio + 1) / math.log(r))\n",
    "\n",
    "def ExtendAndMerge(R, Q, e, bound, calculate_position_func, min_reward, r):\n",
    "    for p in Q.values():\n",
    "        if e.weight >= 0:\n",
    "            q = (p[0] + e.weight, p[1], p, e)\n",
    "        else:\n",
    "            q = (p[0], p[1] - e.weight, p, e)\n",
    "        \n",
    "        if q[1] <= bound:\n",
    "            pos = calculate_position_func(q, min_reward, r)\n",
    "            if pos not in R or R[pos][0] < q[0]:\n",
    "                R[pos] = q\n",
    "\n",
    "def reconstruct_path(p):\n",
    "    path = []\n",
    "    while p[2] is not None:\n",
    "        path.append(p[3])\n",
    "        p = p[2]\n",
    "    return list(reversed(path))\n",
    "\n",
    "def ModifiedSSMOSP(G, s, t, bound, calculate_position_func, r):\n",
    "    TopOrder = G.topological_sort()\n",
    "    Π = {v: {} for v in range(G.V)}\n",
    "    Π[s][0] = (0, 0, None, None)\n",
    "\n",
    "    # Calculate minimum reward across all edges in the graph\n",
    "    min_reward = abs(min(edge.weight for edges in G.adj.values() for edge in edges))\n",
    "\n",
    "    for v in TopOrder:\n",
    "        for e in G.incoming[v]:\n",
    "            ExtendAndMerge(Π[v], Π[e.u], e, bound, calculate_position_func, min_reward, r)\n",
    "    \n",
    "    if Π[t]:\n",
    "        best_path = max(Π[t].values(), key=lambda p: p[0])\n",
    "        return best_path[0], reconstruct_path(best_path)\n",
    "    else:\n",
    "        return None, []\n",
    "\n",
    "# Load the JSON data generated by the previous program\n",
    "with open(\"graph_data.json\", \"r\") as f:\n",
    "    edges = json.load(f)\n",
    "\n",
    "nodes = list(set([u.split(\",\")[0] for u in edges] + [v.split(\",\")[1] for v in edges]))\n",
    "graph = Graph(nodes)\n",
    "\n",
    "for edge, weight in edges.items():\n",
    "    u, v = edge.split(\",\")\n",
    "    graph.add_edge(u, v, weight)\n",
    "\n",
    "# Source, target, bound, and approximation ratio\n",
    "source = \"n0\"\n",
    "target = f\"n{len(nodes)-1}\"\n",
    "bound = 50  # as per the constraints\n",
    "approximation_ratio = 2  # user-defined error ratio\n",
    "\n",
    "# Run ModifiedSSMOSP with the new `calculate_position_custom` function\n",
    "source_idx = graph.node_map[source]\n",
    "target_idx = graph.node_map[target]\n",
    "\n",
    "print(\"Using Custom Logarithmic Bucketing:\")\n",
    "max_reward, path = ModifiedSSMOSP(graph, source_idx, target_idx, bound, calculate_position_custom, approximation_ratio)\n",
    "if path:\n",
    "    path_edges = [(graph.reverse_node_map[edge.u], graph.reverse_node_map[edge.v], edge.weight) for edge in path]\n",
    "    print(f\"Maximum Reward: {max_reward}\")\n",
    "    print(\"Path:\", path_edges)\n",
    "else:\n",
    "    print(\"No feasible path found within the bound.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257273e-52bf-4e88-afdb-efd4e85fe003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047d3f42-4d18-4ba0-aab4-fee71c5daeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-06-19\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (linux64 - \"Ubuntu 24.04.1 LTS\")\n",
      "\n",
      "CPU model: AMD Ryzen 3 3250U with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 2 physical cores, 4 logical processors, using up to 4 threads\n",
      "\n",
      "Optimize a model with 10001 rows, 500000 columns and 1248374 nonzeros\n",
      "Model fingerprint: 0x5a767996\n",
      "Variable types: 0 continuous, 500000 integer (500000 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+02]\n",
      "  Objective range  [1e+00, 1e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 6628 rows and 443013 columns\n",
      "Presolve time: 4.94s\n",
      "Presolved: 3373 rows, 56987 columns, 142078 nonzeros\n",
      "Variable types: 0 continuous, 56987 integer (56987 binary)\n",
      "Found heuristic solution: objective 526.0000000\n",
      "Found heuristic solution: objective 711.0000000\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.7644000e+05   6.110000e+03   0.000000e+00      5s\n",
      "    1853    1.2910000e+03   0.000000e+00   0.000000e+00      5s\n",
      "\n",
      "Root relaxation: objective 1.291000e+03, 1853 iterations, 0.04 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    1291.0000000 1291.00000  0.00%     -    5s\n",
      "\n",
      "Explored 1 nodes (1853 simplex iterations) in 5.51 seconds (3.16 work units)\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 3: 1291 711 526 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.291000000000e+03, best bound 1.291000000000e+03, gap 0.0000%\n",
      "Best path:\n",
      "n0 -> n5653 (weight: -76)\n",
      "n5653 -> n5415 (weight: -96)\n",
      "n5415 -> n8858 (weight: 67)\n",
      "n8858 -> n3364 (weight: -2)\n",
      "n3364 -> n8581 (weight: 90)\n",
      "n8581 -> n5674 (weight: -27)\n",
      "n5674 -> n6008 (weight: 38)\n",
      "n6008 -> n5515 (weight: 84)\n",
      "n5515 -> n6669 (weight: 62)\n",
      "n6669 -> n5866 (weight: 66)\n",
      "n5866 -> n6175 (weight: 92)\n",
      "n6175 -> n697 (weight: 78)\n",
      "n697 -> n6446 (weight: -47)\n",
      "n6446 -> n86 (weight: -8)\n",
      "n86 -> n1303 (weight: 86)\n",
      "n1303 -> n3590 (weight: -77)\n",
      "n3590 -> n4246 (weight: -20)\n",
      "n4246 -> n2436 (weight: 61)\n",
      "n2436 -> n9744 (weight: 66)\n",
      "n9744 -> n6993 (weight: 78)\n",
      "n6993 -> n8633 (weight: -74)\n",
      "n8633 -> n4979 (weight: 35)\n",
      "n4979 -> n2107 (weight: 99)\n",
      "n2107 -> n4350 (weight: -39)\n",
      "n4350 -> n8708 (weight: -63)\n",
      "n8708 -> n6812 (weight: 44)\n",
      "n6812 -> n1653 (weight: 58)\n",
      "n1653 -> n594 (weight: 6)\n",
      "n594 -> n4413 (weight: 21)\n",
      "n4413 -> n1373 (weight: -77)\n",
      "n1373 -> n4688 (weight: -78)\n",
      "n4688 -> n5386 (weight: 84)\n",
      "n5386 -> n1533 (weight: -33)\n",
      "n1533 -> n3890 (weight: 12)\n",
      "n3890 -> n9999 (weight: 64)\n",
      "Total reward: 1291\n",
      "Total negative weight: 717\n",
      "Total Execution Time: 220.20403218269348 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Profile the code\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "### modified code so that it only generates DAGs \n",
    "\n",
    "import random\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import json\n",
    "\n",
    "# Generate a DAG with random edges and weights\n",
    "def generate_dag(num_nodes, num_edges):\n",
    "    nodes = [f'n{i}' for i in range(num_nodes)]\n",
    "    \n",
    "    # Assign topological order to nodes (just shuffle them)\n",
    "    topological_order = nodes.copy()\n",
    "    random.shuffle(topological_order)\n",
    "    \n",
    "    edges = {}\n",
    "    while len(edges) < num_edges:\n",
    "        u, v = random.sample(topological_order, 2)\n",
    "        # Ensure the edge follows topological order (u appears before v)\n",
    "        if topological_order.index(u) < topological_order.index(v):\n",
    "            if (u, v) not in edges:\n",
    "                weight = random.randint(-100, 100)\n",
    "                edges[(u, v)] = weight\n",
    "    return nodes, edges\n",
    "\n",
    "# Parameters\n",
    "num_nodes = 10000\n",
    "num_edges = 500000\n",
    "nodes, edges = generate_dag(num_nodes, num_edges)\n",
    "C = 1000\n",
    "\n",
    "# Save the generated graph (edges) to a JSON file for the second program\n",
    "edges_str_keys = {f\"{u},{v}\": weight for (u, v), weight in edges.items()}\n",
    "with open(\"graph_data.json\", \"w\") as f:\n",
    "    json.dump(edges_str_keys, f)\n",
    "\n",
    "# Convert edges to (reward, loss) format\n",
    "converted_edges = {}\n",
    "for (u, v), weight in edges.items():\n",
    "    if weight > 0:\n",
    "        converted_edges[(u, v)] = (weight, 0)\n",
    "    else:\n",
    "        converted_edges[(u, v)] = (0, -weight)\n",
    "\n",
    "# Create a new model\n",
    "m = gp.Model()\n",
    "\n",
    "# Create variables\n",
    "x = {}\n",
    "for u, v in converted_edges:\n",
    "    x[u, v] = m.addVar(vtype=GRB.BINARY, name=f\"x_{u}_{v}\")\n",
    "\n",
    "# Set objective function to maximize total reward\n",
    "m.setObjective(gp.quicksum(x[u, v] * converted_edges[u, v][0] for u, v in converted_edges), GRB.MAXIMIZE)\n",
    "\n",
    "# Add constraints\n",
    "source_node = 'n0'\n",
    "target_node = f'n{num_nodes-1}'\n",
    "\n",
    "# Constraint 1: The number of edges leaving source_node is 1\n",
    "m.addConstr(gp.quicksum(x[source_node, v] for v in nodes if (source_node, v) in converted_edges) == 1, \"c1\")\n",
    "\n",
    "# Constraint 2: The number of edges entering target_node is 1\n",
    "m.addConstr(gp.quicksum(x[u, target_node] for u in nodes if (u, target_node) in converted_edges) == 1, \"c2\")\n",
    "\n",
    "# Constraint 3: For all other vertices, the number of edges leaving them equals the number of edges entering them\n",
    "for p in nodes:\n",
    "    if p not in [source_node, target_node]:\n",
    "        m.addConstr(\n",
    "            gp.quicksum(x[p, q] for q in nodes if (p, q) in converted_edges) -\n",
    "            gp.quicksum(x[r, p] for r in nodes if (r, p) in converted_edges) == 0,\n",
    "            f\"flow_{p}\"\n",
    "        )\n",
    "\n",
    "# Constraint: The total loss should be at most C\n",
    "m.addConstr(gp.quicksum(x[u, v] * converted_edges[u, v][1] for u, v in converted_edges) <= C, \"loss_constraint\")\n",
    "\n",
    "# Solve the model\n",
    "m.optimize()\n",
    "\n",
    "# Extract the solution edges\n",
    "solution_edges = []\n",
    "predecessors = {}\n",
    "\n",
    "if m.status == GRB.OPTIMAL:\n",
    "    for u, v in converted_edges:\n",
    "        if x[u, v].X > 0.5:  # If the edge is selected in the optimal solution\n",
    "            solution_edges.append((u, v))\n",
    "            predecessors[u] = v  # Track the next node for each node\n",
    "\n",
    "    # Reconstruct the path from the source node 'n0' to the target node\n",
    "    best_path = []\n",
    "    current_node = source_node\n",
    "\n",
    "    while current_node in predecessors:\n",
    "        next_node = predecessors[current_node]\n",
    "        best_path.append((current_node, next_node))\n",
    "        current_node = next_node\n",
    "\n",
    "    # Print the best path in the correct order (starting from the source)\n",
    "    print(\"Best path:\")\n",
    "    total_reward = 0\n",
    "    total_negative_weight = 0\n",
    "    for u, v in best_path:\n",
    "        reward, loss = converted_edges[u, v]\n",
    "        print(f\"{u} -> {v} (weight: {reward if reward > 0 else -loss})\")\n",
    "        if reward > 0:\n",
    "            total_reward += reward\n",
    "        if loss > 0:\n",
    "            total_negative_weight += loss\n",
    "\n",
    "    # Print total reward and total negative weight\n",
    "    print(f\"Total reward: {total_reward}\")\n",
    "    print(f\"Total negative weight: {total_negative_weight}\")\n",
    "else:\n",
    "    print(\"No valid path found\")\n",
    "\n",
    "\n",
    "\n",
    "# Stop profiling\n",
    "profiler.disable()\n",
    "\n",
    "# Calculate total execution time\n",
    "end_time = time.time()\n",
    "total_execution_time = end_time - start_time\n",
    "\n",
    "# Print execution time\n",
    "print(f\"Total Execution Time: {total_execution_time} seconds\")\n",
    "\n",
    "# Print detailed profiling statistics\n",
    "#stats = pstats.Stats(profiler).sort_stats('cumulative')\n",
    "#stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a81110-3ebb-4491-9676-602cec73813f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03efadc1-b358-4d22-91fc-4cb4055f8294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
